{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede9d298",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pngimg.me/thumb/f/720/comvecteezy492057.jpg\" style=\"float: left; margin: 20px; height: 85px\">\n",
    "\n",
    "# Classification Project\n",
    "## Relationship Status Group Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af8e01",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1 - Scraping Data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a0dee",
   "metadata": {},
   "source": [
    "# Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01b216",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px;\"> \n",
    "    \n",
    "The objective of this project is to leverage data scraping techniques to gather online posts and classify them into married or dating groups. This initiative aims to enhance the functionality of a psychological and emotional support app by providing tailored resources. <br><br>\n",
    "    By utilizing machine learning algorithms and natural language processing (NLP) techniques, I seek to develop a robust classification system that accurately categorizes online posts, enabling the app to offer personalized assistance to individuals navigating the complexities of romantic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d77c10",
   "metadata": {},
   "source": [
    "# Packages Import and Data Access Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b86a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '../../project-3')\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from credentials import gf_id, gf_secret, gf_agent, gf_username, gf_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce138003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.0 of praw is outdated. Version 7.7.1 was released Tuesday July 11, 2023.\n"
     ]
    }
   ],
   "source": [
    "# accessing reddit through PRAW with the required credentials\n",
    "reddit = praw.Reddit(\n",
    "client_id = gf_id,\n",
    "client_secret = gf_secret,\n",
    "user_agent = gf_agent,\n",
    "username = gf_username,\n",
    "password = gf_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c76866",
   "metadata": {},
   "source": [
    "# Scraping subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93d95b",
   "metadata": {},
   "source": [
    "- <span style=\"font-size: 16px;\"> Getting top posts of different timelines \n",
    "- <span style=\"font-size: 16px;\"> Getting title, text of posts and the respective subreddit, which is the target of this project <br>  \n",
    "- <span style=\"font-size: 16px;\"> Creating data extracted in one dataframe for each subreddit\n",
    "- <span style=\"font-size: 16px;\"> Combining groups' dataframes in one dataframe and exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7893db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that filters the posts to get only the title, self text and subreddit\n",
    "def combine_data(posts):\n",
    "    data = []\n",
    "    for post in posts:\n",
    "        data.append([post.title, post.selftext, post.subreddit])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a30f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subreddits_scraping(subreddits, folder):\n",
    "    \n",
    "    files = os.listdir(folder)\n",
    "    doc = '_'.join(subreddits)\n",
    "    \n",
    "    if '.ipynb_checkpoints' in files:\n",
    "        files.remove('.ipynb_checkpoints')\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        # extracting the informations of the subreddit\n",
    "        subreddit = reddit.subreddit(sub)\n",
    "\n",
    "        # getting the top 1000 posts of different timelines\n",
    "        posts_con = subreddit.controversial(limit=1000)\n",
    "        posts_top_year = subreddit.top(limit=1000, time_filter=\"year\")\n",
    "        posts_top_month = subreddit.top(limit=1000, time_filter=\"month\")\n",
    "        posts_top_week = subreddit.top(limit=1000, time_filter=\"week\")\n",
    "\n",
    "        # filtering the infos to get only the title, self text and subreddit the posts came from\n",
    "        data_con = combine_data(posts_con)\n",
    "        data_top_year = combine_data(posts_top_year)\n",
    "        data_top_month = combine_data(posts_top_month) \n",
    "        data_top_week = combine_data(posts_top_week)\n",
    "        \n",
    "        # combining the extracted infos of all the posts into a dataframe\n",
    "        df = pd.DataFrame(data_con + data_top_year + data_top_month + data_top_week, columns = ['title', 'self_text', 'subreddit'])\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        # getting the extration time info\n",
    "        time_now = datetime.now().strftime('%d-%m-%H-%M')\n",
    "        \n",
    "        # exporting the dataframe to a csv file with the extraction time info\n",
    "        df.to_csv(folder+'/'+sub+time_now+'.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "    # looping through the csv files to concatenate all the dataframes from the different extraction times\n",
    "    subs = pd.concat([pd.read_csv(folder+'/'+file) for file in files])\n",
    "    subs = subs[['title', 'self_text', 'subreddit']]\n",
    "    subs.drop_duplicates(inplace=True)\n",
    "    subs.to_csv(folder+'/'+doc+'.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a24d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the subreddits and combining all posts in one csv file in scrapes folder\n",
    "subreddits_scraping(['marriage', 'dating'],'../scrapes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3c3f6",
   "metadata": {},
   "source": [
    "# Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e0dad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does it mean when a girl says I don’t fee...</td>\n",
       "      <td>I had a date yesterday and I thought it was ok...</td>\n",
       "      <td>dating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why do some guys get hurt/bothered if you slee...</td>\n",
       "      <td>My ex recently found out I hooked up with some...</td>\n",
       "      <td>dating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worst era to ever date in as a guy.</td>\n",
       "      <td>Is there a single (attractive) young woman (ea...</td>\n",
       "      <td>dating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do some men hate \"Vanilla women\"?</td>\n",
       "      <td>Hiya. Earlier today I got called a \"vanilla wo...</td>\n",
       "      <td>dating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guys the Victim mentality WONT help you</td>\n",
       "      <td>I've been couple of years in this sub and that...</td>\n",
       "      <td>dating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What does it mean when a girl says I don’t fee...   \n",
       "1  why do some guys get hurt/bothered if you slee...   \n",
       "2                Worst era to ever date in as a guy.   \n",
       "3              Why do some men hate \"Vanilla women\"?   \n",
       "4            Guys the Victim mentality WONT help you   \n",
       "\n",
       "                                           self_text subreddit  \n",
       "0  I had a date yesterday and I thought it was ok...    dating  \n",
       "1  My ex recently found out I hooked up with some...    dating  \n",
       "2  Is there a single (attractive) young woman (ea...    dating  \n",
       "3  Hiya. Earlier today I got called a \"vanilla wo...    dating  \n",
       "4  I've been couple of years in this sub and that...    dating  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the csv with all posts and subreddits to check nulls and proportion of subreddits\n",
    "marriage_dating = pd.read_csv('../scrapes/marriage_dating.csv')\n",
    "marriage_dating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d704735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13649, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking size of dataframe with all posts\n",
    "marriage_dating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57095ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dating      0.570015\n",
       "Marriage    0.429985\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data balance\n",
    "marriage_dating['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3002e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          1\n",
       "self_text    401\n",
       "subreddit      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "marriage_dating.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc522fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "self_text    0\n",
       "subreddit    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping null values\n",
    "marriage_dating.dropna(inplace=True)\n",
    "marriage_dating.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ca3ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dating      0.58697\n",
       "Marriage    0.41303\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data balance after removing null values\n",
    "marriage_dating['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b13fd",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45aece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data to csv\n",
    "marriage_dating.to_csv('../output/marriage_dating.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
